\chapter{Approximating the Integrated Likelihood Function}

\section{The Zero-Score Expectation Parameter}

Let $\psi = \varphi(\symbf{\theta})$ and $\lambda$ denote the parameter of interest and nuisance parameter, respectively, for some statistical model $(\mathcal{S}, \mathcal{P_{\symbf{\theta}}})$. Then the general expression to obtain an integrated likelihood for $\psi$ may be written as $$\bar{L}(\psi) = \int_{\Lambda}L(\psi, \lambda)\pi(\lambda|\psi)d\lambda,$${#eq-IL}
where $\pi(\lambda|\psi)$ is a conditional prior density for $\lambda$ given $\psi$. 

@severini2007 considered the problem of selecting $\pi(\lambda|\psi)$ such that when the likelihood function is integrated with respect to this density, the result is useful for non-Bayesian inference. To do this, he outlined four properties (see Appendix \ref{appendix:B}) that an integrated likelihood function must satisfy if it is to be of any use. He went on to prove that an integrated likelihood satisfying these properties could be obtained by first constructing a new nuisance parameter $\phi \in \Phi$ that is unrelated to the parameter of interest (in the sense that its maximum likelihood estimator remains roughly constant for all values of $\psi$)  and then choosing a prior density $\pi(\phi)$ that is independent of $\psi$. Once chosen, the desired integrated likelihood function for $\psi$ is given by $$\bar{L}(\psi) = \int_{\Phi} \tilde{L}(\psi, \phi) \pi(\phi) d\phi,$${#eq-ZSE_IL1} where $\tilde{L}(\psi, \phi)$ is the likelihood function for the model after it has been reparameterized in terms of $\phi$.  It is important to note that the exact choice of prior density for $\phi$ is not particularly important; the only restriction we place upon it is that it must not depend on $\psi$.  

Suppose that we have an explicit parameter of interest and nuisance parameter, so that $\symbf{\theta} = (\psi, \lambda)$. Then @severini2007 defines this new nuisance parameter $\phi$ as the solution to the equation $$\mathbbm{E}(\ell_{\lambda}(\psi, \lambda); \psi_0, \lambda_0)\bigg|_{(\psi_0, \lambda_0) = (\hat{\psi}, \phi)} = 0,$${#eq-zse} where $\ell_{\lambda}(\psi, \lambda) = \frac{\partial \ell(\psi, \lambda)}{\partial \lambda}$, $\psi_0$ and $\lambda_0$ denote the true values of $\psi$ and $\lambda$, and $\hat{\psi}$ is the MLE for $\psi_0$. In other words, for a particular value of $(\psi, \lambda, \hat{\psi})$, we can find the corresponding value of $\phi$ by solving for it in @eq-zse. $\phi$ is called the *zero-score expectation* (ZSE) parameter because it is defined as the value that makes the expectation of the score function (where the derivative is taken with respect to $\lambda$) evaluated at the point $(\hat{\psi}, \phi)$ equal to zero. 
Note that $\phi$ is a function of the data through $\hat{\psi}$. Normally we avoid creating such dependencies in our parameters as it renders them useless for the purpose of parameterizing a statistical model. However, from the perspective of the likelihood function, once the data have been collected they are considered fixed in place and there is no issue with using a quantity such as $\phi$ that depends on the data to parameterize it.

For a given value of $(\psi, \phi, \hat{\psi})$, it is also possible to solve @eq-zse for $\lambda$. This allows us to write @eq-ZSE_IL1 in terms of $L(\psi, \lambda)$: $$\bar{L}(\psi) = \int_{\Phi} L(\psi, \lambda(\psi, \phi)) \pi(\phi) d\phi.$${#eq-ZSE_IL2} 

@severini2018 proved that reparameterizing the nuisance parameter in terms of the ZSE parameter yields the same desirable properties in the subsequent integrated likelihood when $\psi$ and $\lambda$ are implicit. Suppose $\psi$ = $\varphi(\symbf{\theta})$, for some function $\varphi: \symbf{\theta} \to \Psi$, and consider the set of all values of $\symbf{\theta}$ satisfying $\varphi(\symbf{\theta}) = \hat{\psi}$. Call this set $\Omega_{\hat{\psi}}$ so that $$\Omega_{\hat{\psi}} = \Big\{\omega \in \symbf{\theta}: \varphi(\omega) = \hat{\psi}\Big\}.$${#eq-omega_psi_hat} Elements of $\Omega_{\hat{\psi}}$ take the form $(\hat{\psi}, \phi)$, where $\phi \in \Lambda$.

\subsection{Weight Functions}

\section{Two-Index Asymptotics}

Earlier we discussed the one-index asymptotics setting, in which the sample size ($n$) of the model diverged to infinity while the dimension of the nuisance parameter ($q$) remained fixed. Now we turn our attention to the two-index asymptotics setting which describes the behavior of likelihood and pseudolikelihood functions as $n$ and $q$ both tend to infinity, with $q$ growing at least as fast as $n$. Under such a framework, @DeBin2015 showed that estimates for $\psi$ based on a suitably constructed integrated likelihood function will outperform those coming from more traditional pseudolikelihoods, such as the profile likelihood. Such findings provide the motivation for our ensuing examination of two-index asymptotics theory, insofar as it relates to the performance of the integrated likelihood function as a method of inference regarding a parameter of interest.

To mirror the strategy used by @Sartori2003 and @DeBin2015, we will frame our discussion in terms of a stratified sample of data in which each stratum contributes one component to the overall nuisance parameter. Consider a model with parameter $\symbf{\theta} = (\psi, \lambda)$ where $\psi$ is the parameter of interest and $\lambda = (\lambda_1, ..., \lambda_q)$ is a $q$-dimensional nuisance parameter. For the sake of reducing complexity in our notation, we will only consider the case in which $\psi$ and the individual components of $\lambda$ are scalar parameters, though the results of this section should hold in the case where they are all vectors as well. Suppose that we have divided the model's population into $q$ strata and collected a sample of size $m_i$ from each stratum such that observation $j$ from stratum $i$ may be modeled as $$X_{ij} \sim p_{ij}(x_{ij}; \psi, \lambda_i),$${#eq-2idx_model} where $i = 1, ..., q$ and $j = 1, ..., n_i$, making the total sample size $n = \sum_{i = 1}^q m_i$.^[It will be convenient to work under the restriction that the stratum sample sizes are all identical, meaning there exists some positive integer $m$ such that $m_i = m$ for all $i$. However, as both @Sartori2003 and @DeBin2015 note, we could also assume a looser condition in which $m_i = K_i m$ where $0 < K_i < \infty$ without compromising our results.] Hence, there is a one-to-one correspondence between the strata and the components of $\lambda$; assume that each $\lambda_i \in \Lambda$, where the space $\Lambda$ is the same for all $i$, and they all have the same interpretation within their respective strata.

Assume that all the regularity conditions set forth in Section 3.4 apply, except possibly for RC1) - it is not necessary to assume that the observations are i.i.d. here, and in fact it is perfectly acceptable for the $p_{ij}$'s in @eq-2idx_model to differ from one another. We will also allow for the possibility of dependence among observations within a stratum, though not between them. 

Let $\mathbf{x}_i = (x_{i1}, ..., x_{im})$ denote the sample of observations from stratum $i$, so that their joint density may be written as $p_i(\mathbf{x}_i; \psi, \lambda_i)$. Therefore, the likelihood and log-likelihood for the $i$th stratum are $$L^{(i)}(\psi, \lambda_i) = p_i(\mathbf{x}_i; \psi, \lambda_i),$${#eq-2idx_L_i} and $$\ell^{(i)}(\psi, \lambda_i) = \log L^{(i)}(\psi, \lambda_i),$${#eq-2idx_l_i} respectively. For a particular choice of weight function $g(\lambda_i; \psi)$, the integrated likelihood for $\psi$ in stratum $i$ is given by $$\bar{L}^{(i)}(\psi) = \int_\Lambda L^{(i)}(\psi, \lambda_i) g(\lambda_i; \psi)d\lambda_i.$${#eq-2idx_Lbar_i} 

From here, we proceed by using Laplace's method as described by @Tierney1986 (see Appendix B for a brief review) to obtain an analytic approximation to $\bar{L}^{(i)}(\psi)$. Setting $h(\lambda_i) = -\frac{1}{m} \ell^{(i)}(\psi, \lambda_i)$ and $f(\lambda_i) = g(\lambda_i; \psi)$, we may rewrite the integral in @eq-2idx_Lbar_i as $$\bar{L}^{(i)}(\psi) = \int_{\Lambda} f(\lambda_i) \exp[-mh(\lambda_i)]d\lambda_i.$$ One consequence of the regularity conditions we have assumed is that $L^{(i)}(\psi, \lambda_i)$ is that an MLE for $\symbf{\theta}_0$, $\hat{\symbf{\theta}}$, exists and is unique. This further implies the existence and uniqueness of a conditional MLE for the true value of each stratum-specific nuisance parameter given $\psi$ - denote this value for the $i$th stratum by $\hat{\lambda}_{i\psi}$. By definition this value maximizes $\ell^{(i)}(\psi, \lambda_i)$ as a function of $\lambda_i$, and so it also maximizes $-h(\lambda_i)$ since the two functions differ only by a multiplicative constant $\frac{1}{m}$. 

The Laplace approximation to $\bar{L}^{(i)}(\psi)$ is then given by

$$\hat{\bar{L}}^{(i)}(\psi) = f(\hat{\lambda}_{i\psi})\sqrt{\frac{2 \pi}{m}}\sigma \exp[-mh(\hat{\lambda}_{i\psi})],$${#eq-Laplace1} where 
$$
\begin{aligned}
\sigma &= \Bigg[\frac{\partial^2 h}{\partial \lambda_i^2} \Bigg|_{\lambda_i = \hat{\lambda}_{i\psi}} \Bigg]^{-1/2} \\
       &= \Bigg[-\frac{1}{m}\frac{\partial^2 \ell^{(i)}(\psi, \lambda_i)}{\partial \lambda_i^2} \Bigg|_{\lambda_i = \hat{\lambda}_{i\psi}} \Bigg]^{-1/2} \\
       &= \Bigg[\frac{1}{m} \mathcal{I}(\hat{\lambda}_{i\psi})\Bigg]^{-1/2}.
\end{aligned}$$
Here, $\mathcal{I}(\hat{\lambda}_{i\psi})$ denotes the observed information function for $\lambda_i$ only (i.e. the negative second partial derivative of the log-likelihood with respect to $\lambda_i$) evaluated at $\hat{\lambda}_{i\psi}$. Plugging in the appropriate quantities for $f$, $h$, and $\sigma$ into @eq-Laplace1, we arrive at 
$$
\begin{aligned}
\hat{\bar{L}}^{(i)}(\psi) &= f(\hat{\lambda}_{i\psi})\sqrt{\frac{2 \pi}{m}}\sigma \exp[-mh(\hat{\lambda}_{i\psi})] \\
                          &= g(\hat{\lambda}_{i\psi}; \psi)\sqrt{\frac{2 \pi}{m}} \Bigg[\frac{1}{m} \mathcal{I}(\hat{\lambda}_{i\psi})\Bigg]^{-1/2} \exp\Big\{-m \cdot -\frac{1}{m} \ell^{(i)}(\psi, \hat{\lambda}_{i\psi})\Big\} \\
                          &= \frac{\sqrt{2 \pi}}{m} L^{(i)}(\psi, \hat{\lambda}_{i\psi})g(\hat{\lambda}_{i\psi}; \psi)\big[\mathcal{I}(\hat{\lambda}_{i\psi})\big]^{-1/2} \\
                          &= \frac{\sqrt{2 \pi}}{m} L_P^{(i)}(\psi)g(\hat{\lambda}_{i\psi}; \psi)\big[\mathcal{I}(\hat{\lambda}_{i\psi})\big]^{-1/2},
\end{aligned}
$${#eq-Laplace2} where $L_P^{(i)}(\psi) = L^{(i)}(\psi, \hat{\lambda}_{i\psi})$ is the profile likelihood for $\psi$. The error in this approximation is $$\bar{L}^{(i)}(\psi) = \hat{\bar{L}}^{(i)}(\psi)\Bigg\{1 + O\bigg(\frac{1}{m}\bigg)\Bigg\} \> \>\text{ as } \>  \> m \to \infty.$${#eq-Laplace3}

Let $$\bar{\ell}^{(i)}(\psi) = \log \bar{L}^{(i)}(\psi)$${#eq-2idx_lbar_i} denote the integrated log-likelihood for $\psi$. Putting the results in @eq-Laplace2, @eq-Laplace3, and @eq-2idx_lbar_i together, we have
$$
\begin{aligned}
\bar{\ell}^{(i)}(\psi) &= \log \bar{L}^{(i)}(\psi) &&(\text{by Equation 5.2.8})\\
                       &= \log\Bigg(\hat{\bar{L}}^{(i)}(\psi)\Bigg\{1 + O\bigg(\frac{1}{m}\bigg)\Bigg\}\Bigg) &&(\text{by Equation 5.2.7})\\
                       &= \log \hat{\bar{L}}^{(i)}(\psi) + \log\Bigg\{1 + O\bigg(\frac{1}{m}\bigg)\Bigg\} &&(\text{by Equation 5.2.6})\\
                       &= \log\Bigg\{\frac{\sqrt{2 \pi}}{m} L_P^{(i)}(\psi)g(\hat{\lambda}_{i\psi}; \psi)\big[\mathcal{I}(\hat{\lambda}_{i\psi})\big]^{-1/2} \Bigg\} + O\bigg(\frac{1}{m}\bigg) \\
                       &= \frac{1}{2}\log(2\pi) - \log(m) + \log L_P^{(i)}(\psi) + \log g(\hat{\lambda}_{i\psi}; \psi) - \frac{1}{2}\log \mathcal{I}(\hat{\lambda}_{i\psi}) + O\bigg(\frac{1}{m}\bigg) \\
                       &= \ell_P^{(i)}(\psi) + \log g(\hat{\lambda}_{i\psi}; \psi) - \frac{1}{2}\log \mathcal{I}(\hat{\lambda}_{i\psi}) + \frac{1}{2}\log(2\pi) - \log(m) + O\bigg(\frac{1}{m}\bigg) \> \>\text{ as } \>  \> m \to \infty,
\end{aligned}
$$
where $\ell_P^{(i)}(\psi) = \ell^{(i)}(\psi, \hat{\lambda}_{i\psi})$ is the profile log-likelihood for $\psi$. Since log-likelihoods are equivalent up to additive constants, we can discard the $\frac{1}{2} \log(2\pi)$ and $\log(m)$ terms in the final line above to arrive at our final approximation for the integrated log-likelihood in stratum $i$: $$\hat{\bar{\ell}}^{(i)}(\psi) = \ell_P^{(i)}(\psi) + \log g(\hat{\lambda}_{i\psi}; \psi) - \frac{1}{2}\log \mathcal{I}(\hat{\lambda}_{i\psi}).$${#eq-Laplace4} The error in this approximation is given by $$\bar{\ell}^{(i)}(\psi) = \hat{\bar{\ell}}^{(i)}(\psi) + O\bigg(\frac{1}{m}\bigg).$${#eq-Laplace5}

Since the observations between the strata are independent, we may write the likelihood and log-likelihood functions for the entire model as $$L(\psi, \lambda) = \prod_{i=1}^q L^{(i)}(\psi, \lambda_i)$${#eq-2idx_L} and $$\ell(\psi, \lambda) = \sum_{i=1}^q \ell^{(i)}(\psi, \lambda_i),$${#eq-2idx_l} respectively. If we define the weight function $$G(\lambda; \psi) \equiv \prod_{i=1}^qg(\lambda_i; \psi)$${#eq-2idx_weight} then the integrated likelihood function for $\psi$ becomes separable. That is,
$$
\begin{aligned}
\bar{L}(\psi) &= \int_{\Lambda^q}L(\psi, \lambda) G(\lambda; \psi)d\lambda \\
              &= \int_\Lambda\cdots\int_\Lambda \Bigg[\prod_{i=1}^q L^{(i)}(\psi, \lambda_i)\Bigg] \Bigg[\prod_{i=1}^q g(\lambda_i; \psi)\Bigg]d\lambda_1 \cdots d\lambda_q \\
              &= \prod_{i=1}^q \int_\Lambda L^{(i)}(\psi, \lambda_i)g(\lambda_i; \psi)d\lambda_i \\
              &= \prod_{i=1}^q \bar{L}^{(i)}(\psi).
\end{aligned}
$${#eq-2idx_Lbar}

Let $\bar{\ell}(\psi) = \log \bar{L}(\psi)$ denote the integrated log-likelihood function for $\psi$. Taking the logarithm of both sides in @eq-2idx_Lbar, we have $$\bar{\ell}(\psi) = \sum_{i=1}^q \bar{\ell}^{(i)}(\psi).$${#eq-2idx_lbar} Plugging in our approximation to $\bar{\ell}^{(i)}(\psi)$ and its error term in @eq-Laplace4 and @eq-Laplace5, respectively, yields 
$$
\begin{aligned}
\bar{\ell}(\psi) &= \sum_{i=1}^q\Bigg[\ell_P^{(i)}(\psi) + \log g(\hat{\lambda}_{i\psi}; \psi) - \log \mathcal{I}(\hat{\lambda}_{i\psi}) + O\bigg(\frac{1}{m}\bigg) \Bigg] \\
                 &= \ell_P(\psi) + \sum_{i=1}^q \log g(\hat{\lambda}_{i\psi}; \psi) - \frac{1}{2}\sum_{i=1}^q\log \mathcal{I}(\hat{\lambda}_{i\psi}) + O\bigg(\frac{q}{m}\bigg) \> \>\text{ as } \>  \> m \to \infty.
\end{aligned}
$${#eq-Laplace6}





