\chapter{Approximating the Integrated Likelihood Function}

\section{The Zero-Score Expectation Parameter}

Let $\psi = \varphi(\theta)$ and $\lambda$ denote the parameter of interest and nuisance parameter, respectively, for some statistical model $(\mathcal{S}, \mathcal{P_{\theta}})$. Then the general expression to obtain an integrated likelihood for $\psi$ may be written as $$\bar{L}(\psi) = \int_{\Lambda}L(\psi, \lambda)\pi(\lambda|\psi)d\lambda,$${#eq-IL}
where $\pi(\lambda|\psi)$ is a conditional prior density for $\lambda$ given $\psi$. 

@severini2007 considered the problem of selecting $\pi(\lambda|\psi)$ such that when the likelihood function is integrated with respect to this density, the result is useful for non-Bayesian inference. To do this, he outlined four properties (see Appendix \ref{appendix:B}) that an integrated likelihood function must satisfy if it is to be of any use. He went on to prove that an integrated likelihood satisfying these properties could be obtained by first constructing a new nuisance parameter $\phi \in \Phi$ that is unrelated to the parameter of interest (in the sense that its maximum likelihood estimator remains roughly constant for all values of $\psi$)  and then choosing a prior density $\pi(\phi)$ that is independent of $\psi$. Once chosen, the desired integrated likelihood function for $\psi$ is given by $$\bar{L}(\psi) = \int_{\Phi} \tilde{L}(\psi, \phi) \pi(\phi) d\phi,$${#eq-ZSE_IL1} where $\tilde{L}(\psi, \phi)$ is the likelihood function for the model after it has been reparameterized in terms of $\phi$.  It is important to note that the exact choice of prior density for $\phi$ is not particularly important; the only restriction we place upon it is that it must not depend on $\psi$.  

Suppose that we have an explicit parameter of interest and nuisance parameter, so that $\theta = (\psi, \lambda)$. Then @severini2007 defines this new nuisance parameter $\phi$ as the solution to the equation $$\mathbb{E}(\ell_{\lambda}(\psi, \lambda); \psi_0, \lambda_0)\bigg|_{(\psi_0, \lambda_0) = (\hat{\psi}, \phi)} = 0,$${#eq-zse} where $\ell_{\lambda}(\psi, \lambda) = \frac{\partial \ell(\psi, \lambda)}{\partial \lambda}$, $\psi_0$ and $\lambda_0$ denote the true values of $\psi$ and $\lambda$, and $\hat{\psi}$ is the MLE for $\psi_0$. In other words, for a particular value of $(\psi, \lambda, \hat{\psi})$, we can find the corresponding value of $\phi$ by solving for it in @eq-zse. $\phi$ is called the *zero-score expectation* (ZSE) parameter because it is defined as the value that makes the expectation of the score function (where the derivative is taken with respect to $\lambda$) evaluated at the point $(\hat{\psi}, \phi)$ equal to zero. 

Note that $\phi$ is a function of the data through $\hat{\psi}$. Normally we avoid creating such dependencies in our parameters as it renders them useless for the purpose of parameterizing a statistical model. However, from the perspective of the likelihood function, once the data have been collected they are considered fixed in place and there is no issue with using a quantity such as $\phi$ that depends on the data to parameterize it.

For a given value of $(\psi, \phi, \hat{\psi})$, it is also possible to solve @eq-zse for $\lambda$. This allows us to write @eq-ZSE_IL1 in terms of $L(\psi, \lambda)$: $$\bar{L}(\psi) = \int_{\Phi} L(\psi, \lambda(\psi, \phi)) \pi(\phi) d\phi.$${#eq-ZSE_IL2} 

@severini2018 proved that reparameterizing the nuisance parameter in terms of the ZSE parameter yields the same desirable properties in the subsequent integrated likelihood when $\psi$ and $\lambda$ are implicit. Suppose $\psi$ = $\varphi(\theta)$, for some function $\varphi: \Theta \to \Psi$, and consider the set of all values of $\theta$ satisfying $\varphi(\theta) = \hat{\psi}$. Call this set $\Omega_{\hat{\psi}}$ so that $$\Omega_{\hat{\psi}} = \Big\{\omega \in \Theta: \varphi(\omega) = \hat{\psi}\Big\}.$${#eq-omega_psi_hat} Elements of $\Omega_{\hat{\psi}}$ take the form $(\hat{\psi}, \phi)$, where $\phi \in \Lambda$.

\subsection{Weight Functions}




