---
title: "Integrated Likelihood Inference in Poisson Distributions"
format:
  jasa-pdf:
    keep-tex: true
    journal:
      blinded: false
date: ""
author: 
  name: Timothy Ruel
  affiliations: 
    name: Northwestern University
    department: Department of Statistics and Data Science
abstract: |
  The text of your abstract. 200 or fewer words.
keywords:
  - Directly standardized rate
  - Integrated likelihood ratio statistic
  - Maximum integrated likelihood estimator
  - Profile likelihood
  - Weighted sum
  - Zero score expectation parameter
bibliography: bibliography.bib
indent: true
---

## Introduction {#sec-intro}

Suppose the random variables $N_i$, $i = 1, ..., m,$ each have independent Poisson distributions such that $\text{E}(N_i) = \theta_i$ and $\theta = (\theta_1, ..., \theta_m) \in \Theta \subset \mathbb{R}^m_+$. The purpose of this paper is to consider likelihood-based inference for a real-valued parameter of interest $\psi = g(\theta)$, where $g: \Theta \to \Psi$ is a known twice continuously differentiable function.

The log-likelihood function of the model is given by 

$$
\ell(\theta) = \sum_{i=1}^m \big[N_i \log(\theta_i) - \theta_i\big].
$${#eq-1}
Note that while $\ell$ is a function of the full $m$-dimensional vector parameter $\theta$, $\psi$ is just a scalar. This decrease in dimension induces a nuisance parameter $\lambda$ in the model that typically must be eliminated from the log-likelihood function before inference regarding $\psi$ can be conducted.^[Intuitively, we can think of $\lambda$ as representing the portion of $\theta$ that remains in the other $m-1$ dimensions of $\Theta$ that are not occupied by $\psi$.] Furthermore, $\psi$ need not explicitly be equal to one of the components of $\theta$ but instead may be defined as any function $g$ of $\theta$ satisfying the requirements mentioned above. We refer to $\psi$ and $\lambda$ as being *implicit* parameters in such cases. Note that in general a closed form expression for an implicit nuisance parameter will not exist.

The standard procedure for eliminating $\lambda$ from the log-likelihood function involves choosing some method with which to summarize $\ell(\theta)$ over its possible values while holding $\psi$ fixed in place. This effectively reduces $\ell(\theta)$ to a simpler function depending on $\psi$ alone, having replaced each dimension of $\theta$ that depends on $\lambda$ with a static summary of the values in its parameter space. We call this new function a pseudo-log-likelihood function for $\psi$ and denote its generic form as $\ell(\psi)$. As we encounter specific types of pseudo-log-likelihoods, we will introduce more specialized notation as needed. Note that while it usually has properties resembling one, $\ell(\psi)$ is not itself considered a genuine log-likelihood function, and there will always be some degree of information contained within the data lost as a result of the nuisance parameter's elimination.

Perhaps the most straightforward method of summarization we can use to construct $\ell(\psi)$ is to maximize $\ell(\theta)$ over all possible of values of $\theta$ for a fixed value of $\psi$. This yields what is known as the *profile* log-likelihood function, formally defined as 
$$
\ell_p(\psi) = \sup_{\theta \in \Theta: \> g(\theta) = \psi} \ell(\theta).
$${#eq-2} 

In the case where an explicit nuisance parameter exists, @eq-2 is equivalent to replacing $\lambda$ with its conditional maximum likelihood estimate given $\psi$:
$$
\ell_p(\psi) = \ell(\psi, \hat{\lambda}_{\psi}).
$${#eq-3} 

## Integrated Likelihood Functions

## Application to Poisson Models

We now turn our attention to the task of using the ZSE parameterization to construct an integrated likelihood that can be used to make inferences regarding a parameter of interest derived from the Poisson model described in the introduction. We will 

## Inference for the Weighted Sum of Poisson Means

Consider the task of estimating the weighted sum of a set of Poisson means corresponding to $n$ distinct populations, where $n$ is a known positive integer. Let $\theta_i$ denote the mean of population $i$, and suppose we have drawn an independent sample of size $m_i$ from each population, where $X_{ij}$ represents the $j$th count from the $i$th sample. Then we have 

$$X_{ij} \sim \text{Poisson}(\theta_i), \> \> i = 1, ..., n; \> \> j = 1, ..., m_i.$$

The maximum likelihood estimate (MLE) for $\theta_i$ is simply the sample mean $\hat{\theta}_i = \frac{1}{m_i}\sum_{j=1}^{m_i}X_{ij}$.

Consider the weighted sum $$Y = \sum_{i=1}^n w_iX_i,$$ where each $w_i$ is a known constant greater than zero. 

The purpose of this paper is to consider likelihood- and pseudolikelihood-based inference for the real-valued parameter of interest $$\psi \equiv \text{E}(Y) = \sum_{i=1}^n w_i\theta_i.$$ In particular, we will analyze the performance of point and inverval estimates for $\psi$ based on the integrated likelihood function and a proposed modification to it. Similar estimates obtained from the profile likelihood will be used as a benchmark.

## Examples



