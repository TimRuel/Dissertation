---
title: "Research Update"
author: "Tim Ruel"
date: "Feb 14, 2024"
date-format: "MMM D, YYYY"
format: 
  revealjs:
    theme: [default]
    slide-number: true
    incremental: false
    logo: nulogo.png

include-in-header:
  - text: |
      <style>
      #title-slide .title {
        font-size: 2em;
      }
      .center-xy {
        width: 3000;
        margin: 0;
        position: absolute;
        top: 3%;
        left: -27%;
        -ms-transform: translateY(-50%), translateX(-50%);
        transform: translateY(-50%), translateX(-50%);
      }
      </style>
---

## Topic of Interest

::: {style="font-size: 80%;"}

- The focus of my research over the past ~2.5 years has focused on developing a novel method for eliminating nuisance parameters from a statistical model via integration of the model's likelihood function.

- I chose integration as my summary method of choice because:

  - Integrating is akin to averaging (in the sense of an expected value), which should theoretically outperform other methods due to an average's natural ability to incorporate our uncertainty in the true value of the nuisance parameter.   
  - The resemblance of the expression for likelihood function's integral to that of posterior distribution's normalizing constant suggested the use of Bayesian techniques as a tool for integral approximation would be an avenue worth exploring. 
  
:::

## Setup

Consider a model with 

- parameter $\theta \in \Theta$
- likelihood $L(\theta)$, log-likelihood $\ell(\theta) = \log L(\theta)$
- parameter of interest $\psi = g(\theta)$ for some function $g: \Theta \to \mathbb{R}$
- nuisance parameter $\lambda \in \Lambda$

The goal is to obtain the integrated likelihood function $$\bar{L}(\psi) = \int_{\Lambda} L(\psi, \lambda) \pi(\lambda | \psi)d\theta.$$

## Approximating the Integrated Likelihood

::: {style="font-size: 90%;"}

For a given value of $\psi$, define $$\Omega_{\psi} = \{\omega \in \Theta: g(\omega) = \psi\}$$ $$T_{\psi}(\omega) = \underset{\theta \in \Omega_{\psi}}{\operatorname{argmax}} \> \text{E}(\ell(\theta); \omega), \> \omega \in \Theta$$

We can rewrite the integrated likelihood function as 

$$\bar{L}(\psi) = \int_{\Omega_{\hat{\psi}}} L(T_{\psi}(\omega))h(\omega)d\omega$$ where $h(\cdot)$ is a density on $\Omega_{\hat{\psi}}$ and $\hat{\psi} = g(\hat{\theta})$ is the MLE of $\psi$.

:::

## Approximating the Integrated Likelihood

Define $$Q: \mathcal{U} \to \Omega_{\hat{\psi}}$$ for some set $\mathcal{U}$. If $U$ is a $\mathcal{U}$-valued random variable, then $Q(U)$ is random variable in $\Omega_{\hat{\psi}}$. $$\bar{L}(\psi) = \text{E}(L(T_{\psi}(Q(U))))$$ is then an integrated likelihood with a weight function corresponding to the density of of $Q(U)$.


## Approximating the Integrated Likelihood

Define $\tilde{L}(u; \psi) = L(T_{\psi}(Q(u)))$, $u \in \mathcal{U}$. Then we can write $$\bar{L}(\psi) = \int_{\mathcal{U}} \tilde{L}(u; \psi) \tilde{h}(u)du$$ as the integrated likelihood where $\tilde{h}(\cdot)$ is a density on $\mathcal{U}$. Provided that $\tilde{h}$ doesn't depend on $\psi$, $\bar{L}(\psi)$ will have properties resembling that of a genuine likelihood function.

## Approximating the Integrated Likelihood

::: {style="font-size: 95%;"}

Suppose $\mathcal{U} = \Theta$. Write $$\bar{L}(\psi) = \int_{\mathcal{U}} \frac{\tilde{L}(u; \psi)}{L(u)} L(u)\tilde{h}(u)du.$$

Draw $u_1, u_2, ..., u_m$ from the density proportional to $L(u)\tilde{h}(u)$.

Approximate $\bar{L}(\psi)$ using the simple Monte Carlo estimate $$\frac{1}{m} \sum_{i=1}^m \frac{\tilde{L}(u; \psi)}{L(u)}$$

:::

## A Weighted Sum of Poisson Means

::: {style="font-size: 75%;"}

- Consider a set of independent Poisson random variables with different mean parameters: $$X_i \overset{\text{indep.}}{\sim} \text{Poisson}(\lambda_i), \> \> i = 1, ..., n.$$

- Suppose we are interested in the weighted sum $$Y = \sum_{i=1}^n w_iX_i,$$ where each $w_i$ is known.

- Our parameter of interest is $\psi = \text{E}(Y) = \sum_{i=1}^n w_i\lambda_i.$

- The individual parameters $\lambda_1, ..., \lambda_n$ are nuisance parameters as we are only interested in them to the extent that they affect the value of $\psi$.

:::

## Comparing Pseudolikelihoods

![](Rplot.png)
